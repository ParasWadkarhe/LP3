{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb5e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7820\n",
      "Confusion matrix:\n",
      "[[1301  292]\n",
      " [ 144  263]]\n"
     ]
    }
   ],
   "source": [
    "# Bank churn classifier (neural network using scikit-learn MLP)\n",
    "# Satisfies: read dataset, split features/target, normalize, build model,\n",
    "# implement improvements (handle class imbalance by upsampling minority; enable early stopping),\n",
    "# print accuracy and confusion matrix.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "\n",
    "RND = 42\n",
    "\n",
    "# 1. Read dataset (local preferred; fallback to public mirror)\n",
    "# path = \"Churn_Modelling.csv\"\n",
    "df = pd.read_csv(\"path\")\n",
    "\n",
    "\n",
    "# 2. Feature/target split and basic preprocessing\n",
    "if 'Exited' not in df.columns:\n",
    "    raise RuntimeError(\"Dataset must contain 'Exited' column (target).\")\n",
    "\n",
    "df = df.copy()\n",
    "le = LabelEncoder()\n",
    "df['Gender'] = le.fit_transform(df['Gender'])\n",
    "df = pd.get_dummies(df, columns=['Geography'], drop_first=True)\n",
    "df = df.drop(columns=[c for c in ['CustomerId', 'Surname', 'RowNumber'] if c in df.columns])\n",
    "\n",
    "X = df.drop(columns=['Exited'])\n",
    "y = df['Exited'].astype(int)\n",
    "\n",
    "# stratified train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=RND, stratify=y\n",
    ")\n",
    "\n",
    "# 3. Normalize train and test\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 4. Identify improvement: class imbalance handling -> upsample minority class in training set\n",
    "# Combine X_train and y_train to perform resampling\n",
    "train_df = pd.DataFrame(X_train, columns=X.columns)\n",
    "train_df['Exited'] = y_train.values\n",
    "\n",
    "majority = train_df[train_df['Exited'] == 0]\n",
    "minority = train_df[train_df['Exited'] == 1]\n",
    "\n",
    "if len(minority) == 0:\n",
    "    # if no minority present (unexpected), skip resampling\n",
    "    X_train_res = X_train\n",
    "    y_train_res = y_train\n",
    "else:\n",
    "    minority_upsampled = resample(minority,\n",
    "                                  replace=True,\n",
    "                                  n_samples=len(majority),\n",
    "                                  random_state=RND)\n",
    "    train_balanced = pd.concat([majority, minority_upsampled])\n",
    "    train_balanced = train_balanced.sample(frac=1, random_state=RND).reset_index(drop=True)\n",
    "    y_train_res = train_balanced['Exited'].astype(int)\n",
    "    X_train_res = train_balanced.drop(columns=['Exited']).values\n",
    "\n",
    "# 4. Initialize and build the model (MLP with early stopping)\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=20,\n",
    "    tol=1e-4,\n",
    "    random_state=RND\n",
    ")\n",
    "\n",
    "# Train on the (possibly) resampled training set\n",
    "mlp.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 5. Evaluate: print accuracy score and confusion matrix\n",
    "y_pred = mlp.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22751f74",
   "metadata": {},
   "source": [
    "1. Importing Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "Explanation:\n",
    "\n",
    "os → For handling file paths (not heavily used here).\n",
    "\n",
    "numpy → For numerical operations.\n",
    "\n",
    "pandas → For loading and manipulating the dataset.\n",
    "\n",
    "train_test_split → To split data into training and testing sets.\n",
    "\n",
    "LabelEncoder → Convert categorical text labels (like gender) into numbers.\n",
    "\n",
    "StandardScaler → Normalize features (mean=0, std=1) for faster neural network training.\n",
    "\n",
    "MLPClassifier → Multi-layer Perceptron (neural network) classifier.\n",
    "\n",
    "accuracy_score, confusion_matrix → Evaluate model performance.\n",
    "\n",
    "resample → Used to handle class imbalance (upsample minority class).\n",
    "\n",
    "2. Set random seed\n",
    "RND = 42\n",
    "\n",
    "\n",
    "Explanation:\n",
    "\n",
    "RND → Ensures reproducibility. Random processes (like shuffling data) give the same result each time.\n",
    "\n",
    "3. Load the dataset\n",
    "df = pd.read_csv(\"path\")\n",
    "\n",
    "\n",
    "Explanation:\n",
    "\n",
    "Reads the Bank Churn dataset CSV into a pandas dataframe.\n",
    "\n",
    "Each row → a customer\n",
    "\n",
    "Columns → customer details like CreditScore, Gender, Geography, Exited (target).\n",
    "\n",
    "4. Basic preprocessing and feature/target split\n",
    "if 'Exited' not in df.columns:\n",
    "    raise RuntimeError(\"Dataset must contain 'Exited' column (target).\")\n",
    "\n",
    "df = df.copy()\n",
    "le = LabelEncoder()\n",
    "df['Gender'] = le.fit_transform(df['Gender'])\n",
    "df = pd.get_dummies(df, columns=['Geography'], drop_first=True)\n",
    "df = df.drop(columns=[c for c in ['CustomerId', 'Surname', 'RowNumber'] if c in df.columns])\n",
    "\n",
    "X = df.drop(columns=['Exited'])\n",
    "y = df['Exited'].astype(int)\n",
    "\n",
    "\n",
    "Explanation:\n",
    "\n",
    "Ensure Exited column exists → target variable (1 = left, 0 = stayed).\n",
    "\n",
    "Gender → Convert 'Male'/'Female' to 0/1.\n",
    "\n",
    "Geography → Convert categorical countries into dummy variables (one-hot encoding), drop first to avoid redundancy.\n",
    "\n",
    "Drop irrelevant columns: CustomerId, Surname, RowNumber → do not help in prediction.\n",
    "\n",
    "X → All features except Exited.\n",
    "\n",
    "y → Target variable (Exited).\n",
    "\n",
    "5. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=RND, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "Explanation:\n",
    "\n",
    "Split data into 80% training, 20% testing.\n",
    "\n",
    "stratify=y → Maintains the proportion of churners/non-churners in train and test sets.\n",
    "\n",
    "6. Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "Explanation:\n",
    "\n",
    "Neural networks work better if features are on the same scale.\n",
    "\n",
    "fit_transform() → Compute mean/std on train data and normalize it.\n",
    "\n",
    "transform() → Apply the same normalization to test data.\n",
    "\n",
    "7. Handle class imbalance (upsampling minority class)\n",
    "train_df = pd.DataFrame(X_train, columns=X.columns)\n",
    "train_df['Exited'] = y_train.values\n",
    "\n",
    "majority = train_df[train_df['Exited'] == 0]\n",
    "minority = train_df[train_df['Exited'] == 1]\n",
    "\n",
    "if len(minority) == 0:\n",
    "    X_train_res = X_train\n",
    "    y_train_res = y_train\n",
    "else:\n",
    "    minority_upsampled = resample(minority,\n",
    "                                  replace=True,\n",
    "                                  n_samples=len(majority),\n",
    "                                  random_state=RND)\n",
    "    train_balanced = pd.concat([majority, minority_upsampled])\n",
    "    train_balanced = train_balanced.sample(frac=1, random_state=RND).reset_index(drop=True)\n",
    "    y_train_res = train_balanced['Exited'].astype(int)\n",
    "    X_train_res = train_balanced.drop(columns=['Exited']).values\n",
    "\n",
    "\n",
    "Explanation:\n",
    "\n",
    "Class imbalance → fewer churners than non-churners. Neural network may ignore minority class.\n",
    "\n",
    "Combine X_train and y_train into one dataframe for resampling.\n",
    "\n",
    "Separate majority class (Exited=0) and minority class (Exited=1).\n",
    "\n",
    "resample() → Upsample minority class with replacement to match majority class size.\n",
    "\n",
    "train_balanced → Shuffled balanced training data.\n",
    "\n",
    "X_train_res → Features for training after resampling.\n",
    "\n",
    "y_train_res → Target for training after resampling.\n",
    "\n",
    "8. Build and train MLP (neural network)\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=20,\n",
    "    tol=1e-4,\n",
    "    random_state=RND\n",
    ")\n",
    "\n",
    "mlp.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "Explanation:\n",
    "\n",
    "hidden_layer_sizes=(64,32) → Two hidden layers: first with 64 neurons, second with 32.\n",
    "\n",
    "activation='relu' → Non-linear activation function.\n",
    "\n",
    "solver='adam' → Optimizer for weight updates.\n",
    "\n",
    "max_iter=500 → Maximum number of epochs.\n",
    "\n",
    "early_stopping=True → Stop training if validation score stops improving.\n",
    "\n",
    "n_iter_no_change=20 → Number of epochs to wait for improvement before stopping.\n",
    "\n",
    "tol=1e-4 → Minimum improvement threshold.\n",
    "\n",
    "fit() → Train the model on the (balanced) training set.\n",
    "\n",
    "9. Evaluate the model\n",
    "y_pred = mlp.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)\n",
    "\n",
    "\n",
    "Explanation:\n",
    "\n",
    "predict() → Predict churn/not-churn on test set.\n",
    "\n",
    "accuracy_score → Overall proportion of correct predictions.\n",
    "\n",
    "confusion_matrix → Shows counts of True Negatives, False Positives, False Negatives, True Positives.\n",
    "\n",
    "Example output of cm:\n",
    "\n",
    "[[TN  FP]\n",
    " [FN  TP]]\n",
    "\n",
    "\n",
    "Helps identify how well the model predicts churners vs non-churners."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
